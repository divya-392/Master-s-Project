{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38995e2",
   "metadata": {},
   "source": [
    "# Tree-Based Models for Intrusion Detection (CICIDS2017 Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8738a0",
   "metadata": {},
   "source": [
    "This notebook focuses on preparing the dataset, cleaning it, splitting into training and testing parts, and then applying feature selection and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693dc852",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3a644",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d3e42",
   "metadata": {},
   "source": [
    "This block imports the warnings module and disables warning messages. It ensures that the notebook output remains clean and readable without unnecessary warning texts during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d764e52f",
   "metadata": {},
   "source": [
    "Here we import the required Python libraries:\n",
    "\n",
    "- `numpy` and `pandas` for numerical operations and data manipulation  \n",
    "- `seaborn` and `matplotlib` for visualization  \n",
    "- `LabelEncoder` from scikit-learn to convert categorical labels into numeric form  \n",
    "- `train_test_split` for dataset splitting  \n",
    "- `classification_report`, `confusion_matrix`, `accuracy_score`, `precision_recall_fscore_support`, `f1_score` for model evaluation  \n",
    "- `DecisionTreeClassifier`, `RandomForestClassifier`, `ExtraTreesClassifier`, and `XGBoost` for classification models  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf0599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dfb97",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa74eab",
   "metadata": {},
   "source": [
    "The sampled CICIDS2017 dataset is loaded into a pandas DataFrame (df) from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76461f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/hp/Downloads/final/Intelligent Intrusion Detection System/Intrusion Detection system/Intrusion-Detection/data/CICIDS2017_sa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1515d1",
   "metadata": {},
   "source": [
    "### 1.3 Normalization and Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af87daf",
   "metadata": {},
   "source": [
    "Min-Max Normalization is applied to all numeric features, scaling values between 0 and 1. This step ensures uniformity across features, preventing large-scale values from dominating smaller ones. Missing values are replaced with 0 for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization\n",
    "numeric_features = df.dtypes[df.dtypes != 'object'].index\n",
    "df[numeric_features] = df[numeric_features].apply(\n",
    "    lambda x: (x - x.min()) / (x.max()-x.min()))\n",
    "# Fill empty values by 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c8fb56",
   "metadata": {},
   "source": [
    "### 1.4 Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990f691",
   "metadata": {},
   "source": [
    "The `Label` column (attack type) is encoded into numeric values using `LabelEncoder`.  \n",
    "\n",
    "- `X` contains the independent variables (features).  \n",
    "- `y` contains the target class labels (dependent variable).  \n",
    "\n",
    "The dataset is split into **80% training** and **20% testing**, with `stratify=y` ensuring that class distribution remains consistent across both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae733f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])\n",
    "X = df.drop(['Label'],axis=1).values\n",
    "y = df.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dbdf94",
   "metadata": {},
   "source": [
    "Displays the dimensions (rows and columns) of the training dataset to confirm successful splitting and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c18370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45328, 77)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5736c6d",
   "metadata": {},
   "source": [
    "Shows the dimensions of the test dataset, ensuring the split is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2d489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11333, 77)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1fc2ab",
   "metadata": {},
   "source": [
    "Counts and displays the frequency of each class in the training dataset. This helps identify class imbalance problems before applying resampling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca48805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18184\n",
       "3    15228\n",
       "5     6357\n",
       "2     2213\n",
       "6     1744\n",
       "1     1573\n",
       "4       29\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3522b8d",
   "metadata": {},
   "source": [
    "### 1.5 Handling Imbalanced Data (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f77462",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Oversampling Technique) is imported and initialized.\n",
    "\n",
    "It generates synthetic samples for under-represented classes to balance the dataset. In this case, class 4 is oversampled to create 1500 new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(n_jobs=-1, sampling_strategy={4:1500}) # Create 1500 samples for the minority class \"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8df89d",
   "metadata": {},
   "source": [
    "This block checks the type, shape, and unique values of y_train. It validates that the labels are encoded properly and ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be1a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(45328,)\n",
      "[0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "print(y_train.shape)\n",
    "print(np.unique(y_train)[:10])   # show first 10 unique labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31b5c19",
   "metadata": {},
   "source": [
    "The training labels (y_train) are encoded again to ensure consistency. Then, SMOTE is applied to oversample the minority classes. \n",
    "\n",
    "This balances the training dataset and helps machine learning models perform better on imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =labelencoder.fit_transform(y_train)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b9b816",
   "metadata": {},
   "source": [
    "Displays the new class distribution in the training dataset after SMOTE.\n",
    "\n",
    "This verifies whether oversampling successfully balanced the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c97958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18184\n",
       "3    15228\n",
       "5     6357\n",
       "2     2213\n",
       "6     1744\n",
       "1     1573\n",
       "4     1500\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
